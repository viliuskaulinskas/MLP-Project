{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:10.981910Z",
     "iopub.status.busy": "2021-03-30T13:11:10.981313Z",
     "iopub.status.idle": "2021-03-30T13:11:27.911560Z",
     "shell.execute_reply": "2021-03-30T13:11:27.910430Z"
    },
    "papermill": {
     "duration": 16.954353,
     "end_time": "2021-03-30T13:11:27.911798",
     "exception": false,
     "start_time": "2021-03-30T13:11:10.957445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install prerequisites\n",
    "\n",
    "# Install PyCocoTools needed for FasterRCNN\n",
    "!pip install git+https://github.com/gautamchitnis/cocoapi.git@cocodataset-master#subdirectory=PythonAPI\n",
    "\n",
    "# Copy useful functions from pytorch vision tools\n",
    "%cp ../input/pytorch-vision-tools/references/detection/*.* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:27.988127Z",
     "iopub.status.busy": "2021-03-30T13:11:27.987307Z",
     "iopub.status.idle": "2021-03-30T13:11:31.605358Z",
     "shell.execute_reply": "2021-03-30T13:11:31.604331Z"
    },
    "papermill": {
     "duration": 3.661865,
     "end_time": "2021-03-30T13:11:31.605491",
     "exception": false,
     "start_time": "2021-03-30T13:11:27.943626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from os import path\n",
    "import torch\n",
    "import torchvision.utils\n",
    "import utils\n",
    "from engine import train_one_epoch, evaluate\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import Adam\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:31.650701Z",
     "iopub.status.busy": "2021-03-30T13:11:31.649963Z",
     "iopub.status.idle": "2021-03-30T13:11:31.652771Z",
     "shell.execute_reply": "2021-03-30T13:11:31.652332Z"
    },
    "papermill": {
     "duration": 0.02751,
     "end_time": "2021-03-30T13:11:31.652886",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.625376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_dictionary = {\n",
    "    0: 'No finding',\n",
    "    1: 'Aortic enlargement',\n",
    "    2: 'Atelectasis',\n",
    "    3: 'Calcification',\n",
    "    4: 'Cardiomegaly',\n",
    "    5: 'Consolidation',\n",
    "    6: 'ILD',\n",
    "    7: 'Infiltration',\n",
    "    8: 'Lung Opacity',\n",
    "    9: 'Nodule/Mass',\n",
    "    10: 'Other lesion',\n",
    "    11: 'Pleural effusion',\n",
    "    12: 'Pleural thickening',\n",
    "    13: 'Pneumothorax',\n",
    "    14: 'Pulmonary fibrosis'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:31.721189Z",
     "iopub.status.busy": "2021-03-30T13:11:31.720408Z",
     "iopub.status.idle": "2021-03-30T13:11:31.722813Z",
     "shell.execute_reply": "2021-03-30T13:11:31.723315Z"
    },
    "papermill": {
     "duration": 0.039154,
     "end_time": "2021-03-30T13:11:31.723447",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.684293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dataset class which defines how to load images,targets for training and validation\n",
    "class VinBigDataset(Dataset):\n",
    "    def __init__(self, img_dir, df, transforms, class_id=None):\n",
    "        self.img_dir = img_dir\n",
    "        if class_id:\n",
    "            df = df[df[\"class_id\"] == class_id]\n",
    "        self.df = df\n",
    "        self.imgs = df[\"image_id\"].unique()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return the number of elements in the dataset\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # The dataset iterates over each image id\n",
    "        # Return the requested image,target from the dataset\n",
    "        \n",
    "        # Get the id of the current image\n",
    "        img_id = self.imgs[idx]\n",
    "        \n",
    "        # Get the rows containing annotations for this image\n",
    "        data_rows = self.df[self.df[\"image_id\"] == img_id]\n",
    "        boxes = data_rows[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values\n",
    "        \n",
    "        # Convert into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        # Load the image\n",
    "        img_path = path.join(self.img_dir, f\"{img_id}.png\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Compute the area of the annotated box\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "        \n",
    "        # Suppose all instances are not crowd (?)\n",
    "        num_objs = len(boxes)\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        labels = torch.tensor(data_rows[\"class_id\"].values, dtype=torch.int64)\n",
    "        \n",
    "        # Define the target for this training data point\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            to_transform = {\n",
    "                'image': np.array(img),\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            transformed = self.transforms(**to_transform)\n",
    "            img = transformed['image']    \n",
    "            target['boxes'] = torch.tensor(transformed['bboxes'])\n",
    "        \n",
    "#         if self.transforms is not None:\n",
    "#             img = self.transforms(img)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:31.770095Z",
     "iopub.status.busy": "2021-03-30T13:11:31.769411Z",
     "iopub.status.idle": "2021-03-30T13:11:31.772301Z",
     "shell.execute_reply": "2021-03-30T13:11:31.771899Z"
    },
    "papermill": {
     "duration": 0.027856,
     "end_time": "2021-03-30T13:11:31.772410",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.744554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create transforms for preprocessing\n",
    "def create_transforms(train):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])\n",
    "#     transforms.Compose([\n",
    "#             transforms.ToTensor(),\n",
    "#        #     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:31.816889Z",
     "iopub.status.busy": "2021-03-30T13:11:31.816221Z",
     "iopub.status.idle": "2021-03-30T13:11:31.819109Z",
     "shell.execute_reply": "2021-03-30T13:11:31.818570Z"
    },
    "papermill": {
     "duration": 0.026959,
     "end_time": "2021-03-30T13:11:31.819231",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.792272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create an instance of the model\n",
    "def create_model():\n",
    "    # The model has 15 classes (14 abnormalities and 1 no abnormality)\n",
    "    num_classes = 15\n",
    "    \n",
    "    # Use resnet50 pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        \n",
    "    # Fetch the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020049,
     "end_time": "2021-03-30T13:11:31.859370",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.839321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:31.915130Z",
     "iopub.status.busy": "2021-03-30T13:11:31.914590Z",
     "iopub.status.idle": "2021-03-30T13:11:32.076203Z",
     "shell.execute_reply": "2021-03-30T13:11:32.076925Z"
    },
    "papermill": {
     "duration": 0.197389,
     "end_time": "2021-03-30T13:11:32.077088",
     "exception": false,
     "start_time": "2021-03-30T13:11:31.879699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training data csv file\n",
    "data_dir = \"../input/vinbig1024stratified-withnih/vinbigstratified_withnih/output/dataset/train\"\n",
    "\n",
    "df_train = pd.read_csv(f\"../input/vinbig1024stratified-withnih/vinbigstratified_withnih/train_sup_with_nih.csv\")\n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train.loc[df_train[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n",
    "\n",
    "# FasterRCNN handles class_id==0 as the background.\n",
    "df_train[\"class_id\"] = df_train[\"class_id\"] + 1\n",
    "df_train.loc[df_train[\"class_id\"] == 15, [\"class_id\"]] = 0\n",
    "\n",
    "# Print out the total number of images and the total number of annotations \n",
    "print(f\"{df_train['image_id'].nunique()} images in training set\")\n",
    "print(f\"{len(df_train.index)} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.123235Z",
     "iopub.status.busy": "2021-03-30T13:11:32.122588Z",
     "iopub.status.idle": "2021-03-30T13:11:32.146546Z",
     "shell.execute_reply": "2021-03-30T13:11:32.147019Z"
    },
    "papermill": {
     "duration": 0.049479,
     "end_time": "2021-03-30T13:11:32.147189",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.097710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['class_id'] != 0]\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.196648Z",
     "iopub.status.busy": "2021-03-30T13:11:32.195895Z",
     "iopub.status.idle": "2021-03-30T13:11:32.203701Z",
     "shell.execute_reply": "2021-03-30T13:11:32.203197Z"
    },
    "papermill": {
     "duration": 0.034573,
     "end_time": "2021-03-30T13:11:32.203830",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.169257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataset and transformations for training and validation\n",
    "\n",
    "train_img_dir = '../input/vinbig1024stratified-withnih/vinbigstratified_withnih/output/dataset/train'\n",
    "# train_img_dir = path.join(data_dir, 'train/train')\n",
    "train_dataset = VinBigDataset(train_img_dir, df_train, create_transforms(train=True))\n",
    "\n",
    "# Create data loaders for the training set. The collate function\n",
    "# defines how to form a minibatch from the indiviaual data items. In our case we\n",
    "# just want to collate them into a single list.\n",
    "\n",
    "data_loader_train = DataLoader(\\\n",
    "    train_dataset, batch_size=5, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
    "\n",
    "# Print the number of elements in the test and training set\n",
    "print(f\"{df_train['image_id'].nunique()} images in training set\")\n",
    "print(f\"{len(df_train.index)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021552,
     "end_time": "2021-03-30T13:11:32.246820",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.225268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.300987Z",
     "iopub.status.busy": "2021-03-30T13:11:32.300415Z",
     "iopub.status.idle": "2021-03-30T13:11:32.327056Z",
     "shell.execute_reply": "2021-03-30T13:11:32.326624Z"
    },
    "papermill": {
     "duration": 0.058832,
     "end_time": "2021-03-30T13:11:32.327175",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.268343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the VALIDATION data csv file\n",
    "data_dir = \"../input/vinbig1024stratified/\"\n",
    "\n",
    "df_val = pd.read_csv(f\"../input/vinbig1024stratified-withnih/vinbigstratified_withnih/val_sup.csv\")\n",
    "df_val.fillna(0, inplace=True)\n",
    "df_val.loc[df_val[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n",
    "\n",
    "# FasterRCNN handles class_id==0 as the background.\n",
    "df_val[\"class_id\"] = df_val[\"class_id\"] + 1\n",
    "df_val.loc[df_val[\"class_id\"] == 15, [\"class_id\"]] = 0\n",
    "\n",
    "# Print out the total number of images and the total number of annotations \n",
    "print(f\"{df_val['image_id'].nunique()} images in validation set\")\n",
    "print(f\"{len(df_val.index)} annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.375605Z",
     "iopub.status.busy": "2021-03-30T13:11:32.374846Z",
     "iopub.status.idle": "2021-03-30T13:11:32.391370Z",
     "shell.execute_reply": "2021-03-30T13:11:32.390971Z"
    },
    "papermill": {
     "duration": 0.042387,
     "end_time": "2021-03-30T13:11:32.391480",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.349093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val = df_val[df_val['class_id'] != 0]\n",
    "df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.443516Z",
     "iopub.status.busy": "2021-03-30T13:11:32.442685Z",
     "iopub.status.idle": "2021-03-30T13:11:32.448091Z",
     "shell.execute_reply": "2021-03-30T13:11:32.447635Z"
    },
    "papermill": {
     "duration": 0.032969,
     "end_time": "2021-03-30T13:11:32.448207",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.415238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataset and transformations for training and validation\n",
    "\n",
    "val_img_dir = '../input/vinbig1024stratified-withnih/vinbigstratified_withnih/output/dataset/validation'\n",
    "# train_img_dir = path.join(data_dir, 'train/train')\n",
    "val_dataset = VinBigDataset(val_img_dir, df_val, create_transforms(train=False))\n",
    "\n",
    "# Create data loaders for the training set. The collate function\n",
    "# defines how to form a minibatch from the indiviaual data items. In our case we\n",
    "# just want to collate them into a single list.\n",
    "\n",
    "data_loader_val = DataLoader(val_dataset, batch_size=5, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
    "\n",
    "# Print the number of elements in the test and training set\n",
    "print(f\"{df_val['image_id'].nunique()} images in validation set\")\n",
    "print(f\"{len(df_val.index)} annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022831,
     "end_time": "2021-03-30T13:11:32.495002",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.472171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:32.546496Z",
     "iopub.status.busy": "2021-03-30T13:11:32.545933Z",
     "iopub.status.idle": "2021-03-30T13:11:39.402851Z",
     "shell.execute_reply": "2021-03-30T13:11:39.403391Z"
    },
    "papermill": {
     "duration": 6.885612,
     "end_time": "2021-03-30T13:11:39.403599",
     "exception": false,
     "start_time": "2021-03-30T13:11:32.517987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "use_pre_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:39.485183Z",
     "iopub.status.busy": "2021-03-30T13:11:39.484416Z",
     "iopub.status.idle": "2021-03-30T13:11:39.624037Z",
     "shell.execute_reply": "2021-03-30T13:11:39.623526Z"
    },
    "papermill": {
     "duration": 0.184932,
     "end_time": "2021-03-30T13:11:39.624172",
     "exception": false,
     "start_time": "2021-03-30T13:11:39.439240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:39.703189Z",
     "iopub.status.busy": "2021-03-30T13:11:39.702368Z",
     "iopub.status.idle": "2021-03-30T13:11:39.704428Z",
     "shell.execute_reply": "2021-03-30T13:11:39.703854Z"
    },
    "papermill": {
     "duration": 0.046733,
     "end_time": "2021-03-30T13:11:39.704588",
     "exception": false,
     "start_time": "2021-03-30T13:11:39.657855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from PIL import ImageDraw\n",
    "# draw = ImageDraw.Draw(image)\n",
    "# for i in range(len(details)):\n",
    "#     draw.rectangle([(details[i:i+1]['x_min'], details[i:i+1]['y_min']), (details[i:i+1]['x_max'], details[i:i+1]['y_max'])], outline =\"red\", width=3)\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T13:11:39.789961Z",
     "iopub.status.busy": "2021-03-30T13:11:39.789043Z",
     "iopub.status.idle": "2021-03-30T17:03:14.286955Z",
     "shell.execute_reply": "2021-03-30T17:03:14.286413Z"
    },
    "papermill": {
     "duration": 13894.545711,
     "end_time": "2021-03-30T17:03:14.287125",
     "exception": false,
     "start_time": "2021-03-30T13:11:39.741414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 25\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = Adam(params, lr=learning_rate, weight_decay=weight_decay)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00002)\n",
    "\n",
    "# checkpoint = torch.load(\"../input/model14/model_14.bin\")\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# last_epoch = checkpoint['epoch']\n",
    "# model.train()\n",
    "# print('Epoch = ', last_epoch)\n",
    "# Create a folder for saving the model weights\n",
    "%mkdir model\n",
    "%mkdir stats\n",
    "\n",
    "train_meters = []\n",
    "coco_evals = []\n",
    "t_start = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train over the epoch\n",
    "    logger = train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=100)\n",
    "    train_meters.append(logger.meters)\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    coco_eval = evaluate(model, data_loader_val, device)\n",
    "    coco_evals.append(coco_eval.coco_eval)\n",
    "    \n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    # Save the stats and model at every epoch from epoch no.9\n",
    "    if epoch > 10:\n",
    "        pickle.dump(train_meters, open(f\"stats/train_stats_{epoch}.pkl\", 'wb'))\n",
    "        pickle.dump(coco_evals, open(f\"stats/val_stats_{epoch}.pkl\", 'wb'))\n",
    "        \n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "        }, f\"model/model_{epoch}.bin\")\n",
    "\n",
    "print('TRAINING AND VALIDATION DONE')\n",
    "t_end = time.time()\n",
    "print(f\"Training took {t_end - t_start}\")\n",
    "\n",
    "t_start = time.time()\n",
    "# Validation statistics for every class at the end\n",
    "coco_evals_class = []\n",
    "for class_id in range(0, 15):\n",
    "    class_val_dataset = VinBigDataset(val_img_dir, df_val, create_transforms(train=False), class_id=class_id)\n",
    "\n",
    "    data_loader_class_val = DataLoader(class_val_dataset, batch_size=5, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
    "    \n",
    "    if len(class_val_dataset) == 0:\n",
    "        continue\n",
    "        \n",
    "    coco_eval_class = evaluate(model, data_loader_class_val, device)\n",
    "    coco_evals_class.append(coco_eval_class.coco_eval)\n",
    "\n",
    "t_end = time.time()\n",
    "print(f\"Validation for every class took {t_end - t_start}\")\n",
    "\n",
    "# Save the model weights\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, f\"model/model.bin\")\n",
    "\n",
    "# Save the stats\n",
    "pickle.dump(train_meters, open(f\"stats/train_stats.pkl\", 'wb'))\n",
    "pickle.dump(coco_evals, open(f\"stats/val_stats.pkl\", 'wb'))\n",
    "pickle.dump(coco_evals_class, open(f\"stats/val_stats_classes.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:03:14.569483Z",
     "iopub.status.busy": "2021-03-30T17:03:14.568558Z",
     "iopub.status.idle": "2021-03-30T17:05:22.038358Z",
     "shell.execute_reply": "2021-03-30T17:05:22.037353Z"
    },
    "papermill": {
     "duration": 127.627349,
     "end_time": "2021-03-30T17:05:22.038506",
     "exception": false,
     "start_time": "2021-03-30T17:03:14.411157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "zip -r -q stats.zip stats/*.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.124819,
     "end_time": "2021-03-30T17:05:22.288349",
     "exception": false,
     "start_time": "2021-03-30T17:05:22.163530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plot statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:22.545349Z",
     "iopub.status.busy": "2021-03-30T17:05:22.544616Z",
     "iopub.status.idle": "2021-03-30T17:05:22.548370Z",
     "shell.execute_reply": "2021-03-30T17:05:22.547968Z"
    },
    "papermill": {
     "duration": 0.135969,
     "end_time": "2021-03-30T17:05:22.548485",
     "exception": false,
     "start_time": "2021-03-30T17:05:22.412516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for getting and plotting training stats\n",
    "\n",
    "def get_train_stats(name, stats):\n",
    "    return [s[name].value for s in stats]\n",
    "\n",
    "def plot_train_stats(train_stats, name):\n",
    "    loss = get_train_stats('loss', train_stats)\n",
    "    loss_classifier = get_train_stats('loss_classifier', train_stats)\n",
    "    loss_box_reg = get_train_stats('loss_box_reg', train_stats)\n",
    "    loss_objectness = get_train_stats('loss_objectness', train_stats)\n",
    "    loss_rpn_box_reg = get_train_stats('loss_rpn_box_reg', train_stats)\n",
    "    # Plot the training stats\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    plt.plot(loss, label='loss')\n",
    "    plt.plot(loss_classifier, label='loss_classifier')\n",
    "    plt.plot(loss_box_reg, label='loss_box_reg')\n",
    "    plt.plot(loss_objectness, label='loss_objectness')\n",
    "    plt.plot(loss_rpn_box_reg, label='loss_rpn_box_reg')\n",
    "    plt.legend()\n",
    "    plt.xticks(range(0, len(loss), 5))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(f'Training stats {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:22.902604Z",
     "iopub.status.busy": "2021-03-30T17:05:22.900883Z",
     "iopub.status.idle": "2021-03-30T17:05:22.903496Z",
     "shell.execute_reply": "2021-03-30T17:05:22.901728Z"
    },
    "papermill": {
     "duration": 0.23143,
     "end_time": "2021-03-30T17:05:22.903706",
     "exception": false,
     "start_time": "2021-03-30T17:05:22.672276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for getting and plotting validation stats\n",
    "\n",
    "def get_val_stats(idx, stats):\n",
    "    return [s['bbox'].stats[idx] for s in stats]\n",
    "\n",
    "def plot_val_stats(val_stats, name):\n",
    "    ap_50_95 = get_val_stats(0, val_stats)\n",
    "    ap_50 = get_val_stats(1, val_stats)\n",
    "    ap_75 = get_val_stats(2, val_stats)\n",
    "    ar_all_md100 = get_val_stats(8, val_stats)\n",
    "\n",
    "     # Plot the validation stats\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    plt.plot(ap_50_95, label='AP .50:.95')\n",
    "    plt.plot(ap_50, label='AP .50')\n",
    "    plt.plot(ap_75, label='AP .75')\n",
    "    plt.plot(ar_all_md100, label='AR All Max Dets 100')\n",
    "    plt.legend()\n",
    "    plt.xticks(range(0, len(ap_50), 5))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(f'Validation stats {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:23.188016Z",
     "iopub.status.busy": "2021-03-30T17:05:23.187143Z",
     "iopub.status.idle": "2021-03-30T17:05:23.551339Z",
     "shell.execute_reply": "2021-03-30T17:05:23.550916Z"
    },
    "papermill": {
     "duration": 0.510368,
     "end_time": "2021-03-30T17:05:23.551464",
     "exception": false,
     "start_time": "2021-03-30T17:05:23.041096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the stats\n",
    "plot_train_stats(train_meters, 'baseline')\n",
    "plot_val_stats(coco_evals, 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:23.824488Z",
     "iopub.status.busy": "2021-03-30T17:05:23.822563Z",
     "iopub.status.idle": "2021-03-30T17:05:23.829495Z",
     "shell.execute_reply": "2021-03-30T17:05:23.830115Z"
    },
    "papermill": {
     "duration": 0.151071,
     "end_time": "2021-03-30T17:05:23.830317",
     "exception": false,
     "start_time": "2021-03-30T17:05:23.679246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in range(15):\n",
    "#     plot_val_stats(coco_evals_class[i], f'baseline class {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:24.283710Z",
     "iopub.status.busy": "2021-03-30T17:05:24.282886Z",
     "iopub.status.idle": "2021-03-30T17:05:24.286624Z",
     "shell.execute_reply": "2021-03-30T17:05:24.287201Z"
    },
    "papermill": {
     "duration": 0.226677,
     "end_time": "2021-03-30T17:05:24.287386",
     "exception": false,
     "start_time": "2021-03-30T17:05:24.060709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# for images, targets in metric_logger.log_every(data_loader_train, 10, header):\n",
    "#     images = list(image.to(device) for image in images)\n",
    "#     targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#     outs = model(images)\n",
    "#     break\n",
    "# print(outs)\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.128029,
     "end_time": "2021-03-30T17:05:24.602377",
     "exception": false,
     "start_time": "2021-03-30T17:05:24.474348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Draw prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:24.870787Z",
     "iopub.status.busy": "2021-03-30T17:05:24.869914Z",
     "iopub.status.idle": "2021-03-30T17:05:24.871864Z",
     "shell.execute_reply": "2021-03-30T17:05:24.872267Z"
    },
    "papermill": {
     "duration": 0.142394,
     "end_time": "2021-03-30T17:05:24.872399",
     "exception": false,
     "start_time": "2021-03-30T17:05:24.730005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# Hyperparameters\n",
    "# learning_rate = 0.0001\n",
    "# weight_decay = 0\n",
    "# num_epochs = 25\n",
    "# params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = Adam(params, lr=learning_rate, weight_decay=weight_decay)\n",
    "# lr_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00002)\n",
    "\n",
    "# checkpoint = torch.load(\"../input/model24/model_24.bin\")\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# last_epoch = checkpoint['epoch']\n",
    "# model.eval()\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:25.134463Z",
     "iopub.status.busy": "2021-03-30T17:05:25.133922Z",
     "iopub.status.idle": "2021-03-30T17:05:25.137536Z",
     "shell.execute_reply": "2021-03-30T17:05:25.137979Z"
    },
    "papermill": {
     "duration": 0.137381,
     "end_time": "2021-03-30T17:05:25.138114",
     "exception": false,
     "start_time": "2021-03-30T17:05:25.000733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loaded_model = create_model()\n",
    "# checkpoint = torch.load(\"model/model.bin\")\n",
    "# loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# %mkdir image_predictions\n",
    "\n",
    "# for idx in range(10):\n",
    "#     img, _ = val_dataset[idx]\n",
    "#     label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#     #put the model in evaluation mode\n",
    "#     loaded_model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         prediction = loaded_model([img])\n",
    "#     image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "#     draw = ImageDraw.Draw(image)\n",
    "\n",
    "#     # draw groundtruth\n",
    "#     for elem in range(len(label_boxes)):\n",
    "#         draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline =\"green\", width=3)\n",
    "\n",
    "#     for element in range(len(prediction[0][\"boxes\"])):\n",
    "#         boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "#         score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 4)\n",
    "#         if score > 0.4:\n",
    "#             draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =\"red\", width =3)\n",
    "#             draw.text((boxes[0], boxes[1]), text = str(score))\n",
    "\n",
    "#     image_name = df_val.at[idx, 'image_id']\n",
    "#     image.save(f\"image_predictions/{image_name}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:25.415017Z",
     "iopub.status.busy": "2021-03-30T17:05:25.414169Z",
     "iopub.status.idle": "2021-03-30T17:05:26.750766Z",
     "shell.execute_reply": "2021-03-30T17:05:26.749812Z"
    },
    "papermill": {
     "duration": 1.483342,
     "end_time": "2021-03-30T17:05:26.750896",
     "exception": false,
     "start_time": "2021-03-30T17:05:25.267554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = create_model()\n",
    "checkpoint = torch.load(\"../input/model14/model_14.bin\")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "%mkdir image_predictions\n",
    "\n",
    "font = ImageFont.truetype('../input/arial-font/arial.ttf', 16)\n",
    "\n",
    "# for idx in range(10):\n",
    "idx = 3\n",
    "img, _ = val_dataset[idx]\n",
    "label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline=(78, 186, 74), width=5)\n",
    "#     draw.text((label_boxes[elem][0], label_boxes[elem][1]-20), text=class_dictionary[val_dataset[idx][1][\"labels\"][elem].item()], font=font)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 3)\n",
    "    if score > 0.4:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=(235, 64, 52), width=3)\n",
    "#         if (boxes[1] + 100 < boxesp[1])\n",
    "        score = \"{:.3f}\".format(score)\n",
    "        text = f'{class_dictionary[prediction[0][\"labels\"][element].item()]} {score}'\n",
    "        size_width, _ = draw.textsize(text, font)\n",
    "        draw.rectangle([(boxes[0], boxes[1]-20), (boxes[0] + size_width, boxes[1])], fill=(235, 64, 52, 127))\n",
    "        draw.text((boxes[0], boxes[1]-20), text=text, font=font)\n",
    "\n",
    "# image_name = df_val.at[idx, 'image_id']\n",
    "# image.save(f\"image_predictions/{image_name}.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:27.377802Z",
     "iopub.status.busy": "2021-03-30T17:05:27.377250Z",
     "iopub.status.idle": "2021-03-30T17:05:32.083617Z",
     "shell.execute_reply": "2021-03-30T17:05:32.084065Z"
    },
    "papermill": {
     "duration": 5.203282,
     "end_time": "2021-03-30T17:05:32.084222",
     "exception": false,
     "start_time": "2021-03-30T17:05:26.880940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 5\n",
    "img, _ = val_dataset[idx]\n",
    "label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline=(78, 186, 74), width=5)\n",
    "#     draw.text((label_boxes[elem][0], label_boxes[elem][1]-20), text=class_dictionary[val_dataset[idx][1][\"labels\"][elem].item()], font=font)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 3)\n",
    "    if score > 0.4:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=(235, 64, 52), width=3)\n",
    "#         if (boxes[1] + 100 < boxesp[1])\n",
    "        score = \"{:.3f}\".format(score)\n",
    "        text = f'{class_dictionary[prediction[0][\"labels\"][element].item()]} {score}'\n",
    "        size_width, _ = draw.textsize(text, font)\n",
    "        draw.rectangle([(boxes[0], boxes[1]-20), (boxes[0] + size_width, boxes[1])], fill=(235, 64, 52, 127))\n",
    "        draw.text((boxes[0], boxes[1]-20), text=text, font=font)\n",
    "\n",
    "# image_name = df_val.at[idx, 'image_id']\n",
    "# image.save(f\"image_predictions/{image_name}.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:32.381846Z",
     "iopub.status.busy": "2021-03-30T17:05:32.380977Z",
     "iopub.status.idle": "2021-03-30T17:05:37.251788Z",
     "shell.execute_reply": "2021-03-30T17:05:37.252206Z"
    },
    "papermill": {
     "duration": 5.026161,
     "end_time": "2021-03-30T17:05:37.252356",
     "exception": false,
     "start_time": "2021-03-30T17:05:32.226195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 6\n",
    "img, _ = val_dataset[idx]\n",
    "label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline=(78, 186, 74), width=5)\n",
    "#     draw.text((label_boxes[elem][0], label_boxes[elem][1]-20), text=class_dictionary[val_dataset[idx][1][\"labels\"][elem].item()], font=font)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 3)\n",
    "    if score > 0.4:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=(235, 64, 52), width=3)\n",
    "#         if (boxes[1] + 100 < boxesp[1])\n",
    "        score = \"{:.3f}\".format(score)\n",
    "        text = f'{class_dictionary[prediction[0][\"labels\"][element].item()]} {score}'\n",
    "        size_width, _ = draw.textsize(text, font)\n",
    "        draw.rectangle([(boxes[0], boxes[1]-20), (boxes[0] + size_width, boxes[1])], fill=(235, 64, 52, 127))\n",
    "        draw.text((boxes[0], boxes[1]-20), text=text, font=font)\n",
    "\n",
    "# image_name = df_val.at[idx, 'image_id']\n",
    "# image.save(f\"image_predictions/{image_name}.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:37.593086Z",
     "iopub.status.busy": "2021-03-30T17:05:37.592511Z",
     "iopub.status.idle": "2021-03-30T17:05:42.038766Z",
     "shell.execute_reply": "2021-03-30T17:05:42.039194Z"
    },
    "papermill": {
     "duration": 4.624706,
     "end_time": "2021-03-30T17:05:42.039341",
     "exception": false,
     "start_time": "2021-03-30T17:05:37.414635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 7\n",
    "img, _ = val_dataset[idx]\n",
    "label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline=(78, 186, 74), width=5)\n",
    "#     draw.text((label_boxes[elem][0], label_boxes[elem][1]-20), text=class_dictionary[val_dataset[idx][1][\"labels\"][elem].item()], font=font)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 3)\n",
    "    if score > 0.4:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=(235, 64, 52), width=3)\n",
    "#         if (boxes[1] + 100 < boxesp[1])\n",
    "        score = \"{:.3f}\".format(score)\n",
    "        text = f'{class_dictionary[prediction[0][\"labels\"][element].item()]} {score}'\n",
    "        size_width, _ = draw.textsize(text, font)\n",
    "        draw.rectangle([(boxes[0], boxes[1]-20), (boxes[0] + size_width, boxes[1])], fill=(235, 64, 52, 127))\n",
    "        draw.text((boxes[0], boxes[1]-20), text=text, font=font)\n",
    "\n",
    "# image_name = df_val.at[idx, 'image_id']\n",
    "# image.save(f\"image_predictions/{image_name}.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-30T17:05:42.414598Z",
     "iopub.status.busy": "2021-03-30T17:05:42.413912Z",
     "iopub.status.idle": "2021-03-30T17:05:48.104524Z",
     "shell.execute_reply": "2021-03-30T17:05:48.105023Z"
    },
    "papermill": {
     "duration": 5.886234,
     "end_time": "2021-03-30T17:05:48.105287",
     "exception": false,
     "start_time": "2021-03-30T17:05:42.219053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 8\n",
    "img, _ = val_dataset[idx]\n",
    "label_boxes = np.array(val_dataset[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image, \"RGBA\")\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]), (label_boxes[elem][2], label_boxes[elem][3])], outline=(78, 186, 74), width=5)\n",
    "#     draw.text((label_boxes[elem][0], label_boxes[elem][1]-20), text=class_dictionary[val_dataset[idx][1][\"labels\"][elem].item()], font=font)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 3)\n",
    "    if score > 0.4:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline=(235, 64, 52), width=3)\n",
    "#         if (boxes[1] + 100 < boxesp[1])\n",
    "        score = \"{:.3f}\".format(score)\n",
    "        text = f'{class_dictionary[prediction[0][\"labels\"][element].item()]} {score}'\n",
    "        size_width, _ = draw.textsize(text, font)\n",
    "        draw.rectangle([(boxes[0], boxes[1]-20), (boxes[0] + size_width, boxes[1])], fill=(235, 64, 52, 127))\n",
    "        draw.text((boxes[0], boxes[1]-20), text=text, font=font)\n",
    "\n",
    "# image_name = df_val.at[idx, 'image_id']\n",
    "# image.save(f\"image_predictions/{image_name}.jpg\")\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14086.047813,
   "end_time": "2021-03-30T17:05:52.250726",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-30T13:11:06.202913",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1cb14d15172a4b0aafa19c94bc1780c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9025de23feca443fba527ad78f5fe782",
       "placeholder": "​",
       "style": "IPY_MODEL_73df974321f14f9c878b2026d033e056",
       "value": "100%"
      }
     },
     "2704baec5c82496bb36d915b3cc05704": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2a628480c0044e5dad68a136754e6517": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "502446b8f9ac4570ac1bea6f2e3bd4db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5748c637f84e4200b3f0293daf668589": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1cb14d15172a4b0aafa19c94bc1780c7",
        "IPY_MODEL_5b0df8c5872f4d03b2d049fa4cb7bfd9",
        "IPY_MODEL_cdf9bbf4122745ab9ce538a8bdf3bc9f"
       ],
       "layout": "IPY_MODEL_502446b8f9ac4570ac1bea6f2e3bd4db"
      }
     },
     "5b0df8c5872f4d03b2d049fa4cb7bfd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d93a15576f904cfbb7003e0f4d70c274",
       "max": 167502836,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2a628480c0044e5dad68a136754e6517",
       "value": 167502836
      }
     },
     "62e556a218744fc697d66638613ec05e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73df974321f14f9c878b2026d033e056": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9025de23feca443fba527ad78f5fe782": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdf9bbf4122745ab9ce538a8bdf3bc9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_62e556a218744fc697d66638613ec05e",
       "placeholder": "​",
       "style": "IPY_MODEL_2704baec5c82496bb36d915b3cc05704",
       "value": " 160M/160M [00:05&lt;00:00, 32.5MB/s]"
      }
     },
     "d93a15576f904cfbb7003e0f4d70c274": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
