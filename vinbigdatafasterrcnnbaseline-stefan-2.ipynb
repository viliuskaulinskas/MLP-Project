{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install prerequisites\n\n# Install PyCocoTools needed for FasterRCNN\n!pip install git+https://github.com/gautamchitnis/cocoapi.git@cocodataset-master#subdirectory=PythonAPI\n\n# Copy useful functions from pytorch vision tools\n%cp ../input/pytorch-vision-tools/references/detection/*.* .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import required libraries\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom PIL import Image\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom os import path\nimport torch\nimport torchvision.utils\nimport utils\nfrom engine import train_one_epoch, evaluate\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.optim import Adam\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport pickle\nimport time\nimport matplotlib.pyplot as plt\nimport tqdm\nimport torch.nn.functional as F","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dataset class which defines how to load images,targets for training and validation\nclass VinBigDataset(Dataset):\n    def __init__(self, img_dir, df, transforms):\n        self.img_dir = img_dir\n        self.df = df\n        self.imgs = df[\"image_id\"].unique()\n        self.transforms = transforms\n        \n    def __len__(self):\n        # Return the number of elements in the dataset\n        return len(self.imgs)\n    \n    def __getitem__(self, idx):\n        # The dataset iterates over each image id\n        # Return the requested image,target from the dataset\n        \n        # Get the id of the current image\n        img_id = self.imgs[idx]\n        \n        # Get the rows containing annotations for this image\n        data_rows = self.df[self.df[\"image_id\"] == img_id]\n        boxes = data_rows[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values\n        \n        # Convert into a torch.Tensor\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        \n        # Load the image\n        img_path = path.join(self.img_dir, f\"{img_id}.png\")\n        img = Image.open(img_path).convert(\"RGB\")\n        \n        # Compute the area of the annotated box\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n        \n        # Suppose all instances are not crowd (?)\n        num_objs = len(boxes)\n        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n        \n        # There is only one class, so labels are all ones\n        #labels = torch.ones((num_objs,), dtype=torch.int64)\n        labels = torch.tensor(data_rows[\"class_id\"].values, dtype=torch.int64)\n        \n        # Define the target for this training data point\n        target = {}\n        target[\"boxes\"] = boxes\n        target[\"labels\"] = labels\n        target[\"image_id\"] = torch.tensor([idx])\n        target[\"area\"] = area\n        target[\"iscrowd\"] = iscrowd\n        \n        if self.transforms is not None:\n            to_transform = {\n                'image': np.array(img),\n                'bboxes': target['boxes'],\n                'labels': labels\n            }\n            transformed = self.transforms(**to_transform)\n            img = transformed['image']    \n            target['boxes'] = torch.tensor(transformed['bboxes'])\n        \n        return img, target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_augmentations(train):\n    if train:\n        return A.Compose([\n                \n                A.RandomSizedBBoxSafeCrop(height=800,width=800, erosion_rate=0.2),\n                A.HorizontalFlip(p=0.5),\n                A.ShiftScaleRotate(p=0.2, rotate_limit=15),\n                A.RandomBrightnessContrast(p=0.4),\n                A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n                ToTensorV2(p=1.0)\n                    \n        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n    else:\n        return A.Compose([\n             A.Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)\n            \n        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weighted_fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n    # type: (Tensor, Tensor, List[Tensor], List[Tensor])\n    \"\"\"\n    Computes the loss for Faster R-CNN.\n    Arguments:\n        class_logits (Tensor)\n        box_regression (Tensor)\n        labels (list[BoxList])\n        regression_targets (Tensor)\n    Returns:\n        classification_loss (Tensor)\n        box_loss (Tensor)\n    \"\"\"\n\n    labels = torch.cat(labels, dim=0)\n    regression_targets = torch.cat(regression_targets, dim=0)\n\n    classification_loss = F.cross_entropy(class_logits.to(device), labels.to(device),\n                                          weight=torch.Tensor(vals).to(device))\n\n    #classification_loss_unweighted = F.cross_entropy(class_logits, labels)\n\n\n    # get indices that correspond to the regression targets for\n    # the corresponding ground truth labels, to be used with\n    # advanced indexing\n    sampled_pos_inds_subset = torch.nonzero(labels > 0).squeeze(1)\n    labels_pos = labels[sampled_pos_inds_subset]\n    N, num_classes = class_logits.shape\n    box_regression = box_regression.reshape(N, -1, 4)\n\n    box_loss = F.smooth_l1_loss(\n        box_regression[sampled_pos_inds_subset, labels_pos],\n        regression_targets[sampled_pos_inds_subset],\n        reduction=\"sum\",\n    )\n    box_loss = box_loss / labels.numel()\n\n    return classification_loss, box_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to create an instance of the model\ndef create_model():\n    # The model has 14 classes\n    num_classes = 15\n    torchvision.models.detection.roi_heads.fastrcnn_loss = weighted_fastrcnn_loss\n    # Use resnet50 pre-trained on COCO\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n        \n    # Fetch the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    \n    # Replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    \n    #model.roi_heads.fastrcnn_loss = weighted_fastrcnn_loss\n    \n    print(model.roi_heads)\n   \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training data csv file\ndata_dir = \"../input/vinbig1024stratified/\"\ncsv_dir = \"../input/vinbig1024stratified-anns-removed\"\n\ndf_train = pd.read_csv(f\"{data_dir}/train.csv\")\ndf_val_1 = pd.read_csv(f\"{data_dir}/validation.csv\")\n#df_val_2 = pd.read_csv(f\"{csv_dir}/val_average.csv\")\n\n# Remove images that do not contain any anomolies\ndf_train = df_train[df_train[\"class_id\"]!=14]\ndf_val_1 = df_val_1[df_val_1[\"class_id\"]!=14]\n#df_val_2 = df_val_2[df_val_2[\"class_id\"]!=14]\n\n# Print out the total number of images and the total number of annotations \nprint(f\"{df_train['image_id'].nunique()} images\")\nprint(f\"{len(df_train.index)} annotations\")\nprint()\nprint(f\"{df_val_1['image_id'].nunique()} images\")\nprint(f\"{len(df_val_1.index)} annotations\")\n\n# print(f\"{df_val_2['image_id'].nunique()} images\")\n# print(f\"{len(df_val_2.index)} annotations\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shift class labels +1 to accounts for class 0 being background class\ndf_train[\"class_id\"] = df_train[\"class_id\"].apply(lambda x: x +1)\n\ndf_val_1[\"class_id\"] = df_val_1[\"class_id\"].apply(lambda x: x +1)\n#df_val_2[\"class_id\"] = df_val_2[\"class_id\"].apply(lambda x: x +1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"class_id\"].value_counts().sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_weighting = 14 * ((1/df_train[\"class_id\"].value_counts())/sum(1/df_train[\"class_id\"].value_counts()))\nloss_weighting = loss_weighting.sort_index()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals = loss_weighting.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals = np.append([1], vals)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an instance of the dataset and transformations for training\n# and validation\nimgs_folder = \"../input/vinbig1024stratified/output/dataset\"\ntrain_img_dir = path.join(imgs_folder, 'train')\nval_img_dir = path.join(imgs_folder, 'validation')\n# train_img_dir = path.join(data_dir, 'train/train')\ntrain_dataset = VinBigDataset(train_img_dir, df_train, create_augmentations(train=True))\nval_dataset_1 = VinBigDataset(val_img_dir, df_val_1, create_augmentations(train=False))\n#val_dataset_2 = VinBigDataset(val_img_dir, df_val_2, create_augmentations(train=False))\n\n# Create data loaders for the training and validation set. The collate function\n# defines how to form a minibatch from the indiviaual data items. In our case we\n# just want to collate them into a single list.\n\ndata_loader_train = DataLoader(\\\n    train_dataset, batch_size=5, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n\ndata_loader_val_1 = DataLoader(\\\n    val_dataset_1, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n\n#data_loader_val_2 = DataLoader(\\\n    #val_dataset_2, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n\n# Print the number of elements in the test and training set\nprint(f\"{len(train_dataset)} items in the training set\")\nprint(f\"{len(val_dataset_1)} items in the validation set 1\")\n#print(f\"{len(val_dataset_1)} items in the validation set 2\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport sys\nimport time\nimport torch\n\nimport torchvision.models.detection.mask_rcnn\n\nfrom coco_utils import get_coco_api_from_dataset\nfrom coco_eval import CocoEvaluator\nimport utils\n\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n    model.train()\n    metric_logger = utils.MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    header = 'Epoch: [{}]'.format(epoch)\n\n    lr_scheduler = None\n    if epoch == 0:\n        warmup_factor = 1. / 1000\n        warmup_iters = min(1000, len(data_loader) - 1)\n\n        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n\n    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        # hacky way of stopping ValueError that occurs\n        try:\n            loss_dict = model(images, targets)\n        except ValueError:\n            continue\n            \n\n\n        losses = sum(loss for loss in loss_dict.values())\n\n        # reduce losses over all GPUs for logging purposes\n        loss_dict_reduced = utils.reduce_dict(loss_dict)\n        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n\n        loss_value = losses_reduced.item()\n\n        if not math.isfinite(loss_value):\n            print(\"Loss is {}, stopping training\".format(loss_value))\n            print(loss_dict_reduced)\n            sys.exit(1)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if lr_scheduler is not None:\n            lr_scheduler.step()\n\n        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n\n    return metric_logger","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\n# Train the model\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel.to(device)\n\n# Hyperparameters\nlearning_rate = 0.001\nweight_decay = 0\nnum_epochs = 25\n\nparams = [p for p in model.parameters() if p.requires_grad]\n\noptimizer = Adam(params, lr=learning_rate, weight_decay=weight_decay)\nlr_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00002)\n\n# Create a folder for saving the model weights\n%mkdir model_weights\n%mkdir stats\n\ntrain_meters = []\ncoco_evals_1 = []\n#coco_evals_2 = []\nt_start = time.time()\nbest_ap_50 = 0\nfor epoch in range(num_epochs):\n    # Train over the epoch\n    logger = train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=100)\n    train_meters.append(logger.meters)\n    \n    \n    # Evaluate on the original validation set\n    coco_eval_1 = evaluate(model, data_loader_val_1, device)\n    coco_evals_1.append(coco_eval_1.coco_eval)\n    \n    \n#     print()\n#     print()\n#     print(\"VALIDATION ON MODIFIED DATASET\")\n#     # Evaluate on the new validation set\n#     coco_eval_2 = evaluate(model, data_loader_val_2, device)\n#     coco_evals_2.append(coco_eval_2.coco_eval)\n\n    # Update the learning rate\n    lr_scheduler.step()\n    \n    if coco_eval_1.coco_eval['bbox'].stats[2] > best_ap_50:\n        best_ap_50 = coco_eval_1.coco_eval['bbox'].stats[2]\n        \n        # Save the model weights\n        torch.save(model.state_dict(), f\"model_weights/model_weights.bin\")\n\n    # Save the stats\n    pickle.dump(train_meters, open(f\"stats/train_stats.pkl\", 'wb'))\n    pickle.dump(coco_evals_1, open(f\"stats/val_stats_1.pkl\", 'wb'))\n    #pickle.dump(coco_evals_2, open(f\"stats/val_stats_2.pkl\", 'wb'))\n\n\nt_end = time.time()\nprint(f\"Training took {t_end - t_start}\")\n      \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}